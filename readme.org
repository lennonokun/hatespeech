* notes

** quantization
- do not use Trainer(precision=...) ???
- peft has better support, but much less flexible otherwise
  - lora vars work as fp32
- adapters has worse support
  - lora vars need to match AutoModel's torch_dtype
  - can fix by manually changing, seems to maybe minorly affect metrics?
- currently heads are still float32, but probably worth it for stability

** compilation
- maybe worth it???
- ~10% speed increase
- yet to try on base-discriminator

** model size
- larger model greatly improves target f1
- comparable label f1 

** hydra
- possible only with train_adapter(list) which gives deprecation warning

** isolation
- todo

** else
- rationale seems to get stuck at 0.6 f1?
- probably heads should have their own learning rate?

* todo

** short-term
- ONLY SET SPECIFICS ACTIVE
- actually save adapters
- re-add VAT + gradnorm, check if worth
- configs as mergable files
- fixed step epochs with equal sampling from datasets?
- task batches should include all dataset labels
- separate data loading into its own module
- update readme papers + datasets

** medium-term
- try more virtual adversarial training
- try label smoothing?
- attention mechanism with rationales?
- rationales mask including not classifying invalid tokens

** long term
- text augmentation
- use hatebase for lexicon features

* papers
  - https://bit.kuas.edu.tw/~jni/2024/vol9/s1/36.JNI-S-2023-08-006.pdf
  - https://arxiv.org/pdf/1806.08028
  
* datasets

** using
- hatexplain
  - pub: https://arxiv.org/pdf/2012.10289.pdf
  - data: https://github.com/punyajoy/HateXplain
  - proportion abusive: 0.57
- measuring hate speech
  - data: https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech

** considering
- large scale crowdsourcing + characterization...
  - pub: https://arxiv.org/pdf/1802.00393.pdf
  - data: https://dataverse.mpi-sws.org/dataset.xhtml?persistentId=doi:10.5072/FK2/ZDTEMN
  - requested data but it says to follow email but i dont see yet
- hateval semeval-2019 task 5?
  - pub: https://www.aclweb.org/anthology/S19-2007
  - proportion abusive: 0.4
  - specific to women and immigrants
  - data link not working?
- ethos: an online hate speech detection dataset (binary)
  - pub: https://arxiv.org/pdf/2006.08328.pdf
  - proportion abusive: 0.33
- twitter sentiment analysis
  - data:
    https://www.kaggle.com/arkhoshghalb/twitter-sentiment-analysis-hatred-speech
  - proportion abusive: 0.07
  - racism/sexism specific

* results

** rolling n=10 normalization + uncertainty weighing + gradient adversarial training

| metrics           | results |
|-------------------+---------|
| test_label_f1     |   0.559 |
| test_rationale_f1 |   0.710 |
| test_target_f1    |   0.688 |

** initial n=10 normalization + uncertainty weighing + gradient adversarial training
| metrics           | results |
|-------------------+---------|
| test_label_f1     |   0.544 |
| test_rationale_f1 |   0.609 |
| test_target_f1    |   0.669 |

** initial n=10 norm (broken) + DWA (T=2) + GAT (eps=0.6)
| metrics           | results |
|-------------------+---------|
| test_label_f1     |   0.541 |
| test_rationale_f1 |   0.671 |
| test_target_f1    |   0.639 |

** initial n=10 norm (broken) + DWA (T=2) + 30 epochs
| metrics           | results |
|-------------------+---------|
| test_label_f1     |   0.572 |
| test_rationale_f1 |   0.798 |
| test_target_f1    |   0.705 |

** initial n=10 norm (fixed) + RW + 10 epochs + r=8 + layers=2
| metrics           | results |
|-------------------+---------|
| test_label_f1     |   0.592 |
| test_rationale_f1 |   0.604 |
| test_score_mse    |   2.031 |
| test_target_f1    |   0.712 |

** initial n=10 norm (fixed) + RW + 20 epochs + r=8 + layers=2

| metrics           | results |
|-------------------+---------|
| test_label_f1     |   0.610 |
| test_rationale_f1 |   0.659 |
| test_score_mse    |   1.936 |
| test_target_f1    |   0.721 |
