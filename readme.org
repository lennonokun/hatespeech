* sketching

model -> task_set -> task -> loss
            L__________________^
	   (effectively flattened)

task_sets are mutually exclusive in data, cannot flatten
should they have a loss coefficient between them?
should be normalized by number of samples (rescale task_set losses)
for now give equal weighing, future: try uncertainty weighing?

* todo

** short-term
- get multi dataset learning working
- separate data loading into its own module
- abstract multi dataset model
- update readme papers + datasets
- stopping callback based on multiple metrics?

** medium-term
- branching adapters
- try more virtual adversarial training
- try label smoothing?
- attention mechanism with rationales?
- rationales mask including not classifying invalid tokens

** long term
- text augmentation
- use hatebase for lexicon features
- dataset combination
  - include dataset origin as input?
  - ^ could fuzzify it so that it works for general also
  - ^ could use TaBERT or use as input in classification head

* papers
  - https://bit.kuas.edu.tw/~jni/2024/vol9/s1/36.JNI-S-2023-08-006.pdf
  - https://arxiv.org/pdf/1806.08028
  
* datasets

- hatexplain
  - pub: https://arxiv.org/pdf/2012.10289.pdf
  - data: https://github.com/punyajoy/HateXplain
  - proportion abusive: 0.57
  - USING
- large scale crowdsourcing + characterization...
  - pub: https://arxiv.org/pdf/1802.00393.pdf
  - data: https://dataverse.mpi-sws.org/dataset.xhtml?persistentId=doi:10.5072/FK2/ZDTEMN
  - requested data but it says to follow email but i dont see yet
- hateval semeval-2019 task 5?
  - pub: https://www.aclweb.org/anthology/S19-2007
  - proportion abusive: 0.4
  - specific to women and immigrants
  - data link not working?
- ethos: an online hate speech detection dataset (binary)
  - pub: https://arxiv.org/pdf/2006.08328.pdf
  - proportion abusive: 0.33
- twitter sentiment analysis
  - data:
    https://www.kaggle.com/arkhoshghalb/twitter-sentiment-analysis-hatred-speech
  - proportion abusive: 0.07
  - racism/sexism specific
- measuring hate speech
  - https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech

* results

** rolling n=10 normalization + uncertainty weighing + gradient adversarial training
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│       test_label_f1       │    0.5586057305335999     │
│     test_rationale_f1     │    0.7104283571243286     │
│      test_target_f1       │    0.6882563233375549     │
└───────────────────────────┴───────────────────────────┘

** initial n=10 normalization + uncertainty weighing + gradient adversarial training
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│       test_label_f1       │    0.5440879464149475     │
│     test_rationale_f1     │    0.6091033816337585     │
│      test_target_f1       │    0.6695500612258911     │
└───────────────────────────┴───────────────────────────┘

** initial n=10 norm (broken) + DWA (T=2) + GAT (eps=0.6)
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│       test_label_f1       │    0.5409799814224243     │
│     test_rationale_f1     │    0.6714811325073242     │
│      test_target_f1       │    0.6392104625701904     │
└───────────────────────────┴───────────────────────────┘

** initial n=10 norm (broken) + DWA (T=2) + 30 epochs
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│       test_label_f1       │    0.5729119777679443     │
│     test_rationale_f1     │    0.7984278202056885     │
│      test_target_f1       │     0.704976499080658     │
└───────────────────────────┴───────────────────────────┘

** initial n=10 norm (fixed) + DWA (T=2) + 10 epochs
