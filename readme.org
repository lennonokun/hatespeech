* todo

- augmentation with constraints to not modify reasonings
- multiple datasets?
- augmentation training method?
  - randomized vs total?
  - if randomized, custom dataloader
- try label smoothing?
- make offensive label just normal to focus on hatespeech?
- attention mechanism with rationales?

- use hatebase for lexicon features
- dataset combination
  - include dataset origin as input?
  - ^ could fuzzify it so that it works for general also
  - ^ could use TaBERT or use as input in classification head

- rationales mask including not classifying invalid tokens

- targets learn so much slower
- targets separate tasks much better?
- probably separate heads bc they might conflict
- 
  
* datasets

- hatexplain
  - pub: https://arxiv.org/pdf/2012.10289.pdf
  - data: https://github.com/punyajoy/HateXplain
  - proportion abusive: 0.57
  - USING
- large scale crowdsourcing + characterization...
  - pub: https://arxiv.org/pdf/1802.00393.pdf
  - data: https://dataverse.mpi-sws.org/dataset.xhtml?persistentId=doi:10.5072/FK2/ZDTEMN
  - requested data but it says to follow email but i dont see yet
- hateval semeval-2019 task 5?
  - pub: https://www.aclweb.org/anthology/S19-2007
  - proportion abusive: 0.4
  - specific to women and immigrants
  - data link not working?
- ethos: an online hate speech detection dataset (binary)
  - pub: https://arxiv.org/pdf/2006.08328.pdf
  - proportion abusive: 0.33
- twitter sentiment analysis
  - data:
    https://www.kaggle.com/arkhoshghalb/twitter-sentiment-analysis-hatred-speech
  - proportion abusive: 0.07
  - racism/sexism specific

* best

with offensive
- test label macro acc: 0.665
- test label macro f1: 0.641
- test target macro acc: 0.614

without offensive:
- test label macro acc: 0.784
- test label macro f1: 0.790
- test rationale macro acc: 0.983
- test rationale macro f1: 0.496
- test target macro acc: 0.961
- test target macro f1: 0.065
