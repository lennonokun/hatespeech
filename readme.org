* todo

- augmentation with constraints to not modify reasonings
- multiple datasets?
- augmentation training method?
  - randomized vs total?
  - if randomized, custom dataloader
- try label smoothing?
- make offensive label just normal to focus on hatespeech?
- attention mechanism with rationales?

- use hatebase for lexicon features
- dataset combination
  - include dataset origin as input?
  - ^ could fuzzify it so that it works for general also
  - ^ could use TaBERT or use as input in classification head

- rationales mask including not classifying invalid tokens

- targets learn so much slower
- targets separate tasks much better?
- probably separate heads bc they might conflict
- 

- current task regularization not that bad, but confusing and probably
  not correct
- look up how to actually do it properly, maybe normalize with
  gradients instead?

* papers
  - https://bit.kuas.edu.tw/~jni/2024/vol9/s1/36.JNI-S-2023-08-006.pdf
  - https://arxiv.org/pdf/1806.08028
  
* datasets

- hatexplain
  - pub: https://arxiv.org/pdf/2012.10289.pdf
  - data: https://github.com/punyajoy/HateXplain
  - proportion abusive: 0.57
  - USING
- large scale crowdsourcing + characterization...
  - pub: https://arxiv.org/pdf/1802.00393.pdf
  - data: https://dataverse.mpi-sws.org/dataset.xhtml?persistentId=doi:10.5072/FK2/ZDTEMN
  - requested data but it says to follow email but i dont see yet
- hateval semeval-2019 task 5?
  - pub: https://www.aclweb.org/anthology/S19-2007
  - proportion abusive: 0.4
  - specific to women and immigrants
  - data link not working?
- ethos: an online hate speech detection dataset (binary)
  - pub: https://arxiv.org/pdf/2006.08328.pdf
  - proportion abusive: 0.33
- twitter sentiment analysis
  - data:
    https://www.kaggle.com/arkhoshghalb/twitter-sentiment-analysis-hatred-speech
  - proportion abusive: 0.07
  - racism/sexism specific

* results

** rolling mean normalization + uncertainty weighing + gradient adversarial training
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│       test_label_f1       │    0.5586057305335999     │
│     test_rationale_f1     │    0.7104283571243286     │
│      test_target_f1       │    0.6882563233375549     │
└───────────────────────────┴───────────────────────────┘

** initial n=10 normalization + uncertainty weighing + gradient adversarial training
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│       test_label_f1       │    0.5440879464149475     │
│     test_rationale_f1     │    0.6091033816337585     │
│      test_target_f1       │    0.6695500612258911     │
└───────────────────────────┴───────────────────────────┘

with offensive
- test label macro acc: 0.665
- test label macro f1: 0.641
- test target macro acc: 0.614

without offensive:
- test label macro acc: 0.784
- test label macro f1: 0.790
- test rationale macro acc: 0.983
- test rationale macro f1: 0.496
- test target macro acc: 0.961
- test target macro f1: 0.065
